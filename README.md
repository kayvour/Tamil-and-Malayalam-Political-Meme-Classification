# ğŸ§  Multimodal Tamil and Malayalam Political Meme Classification using CLIP

A deep learning project for classifying political memes using **image + OCR text fusion** with OpenAI CLIP embeddings and a custom neural network classifier.

This system supports:

- âœ… English political memes  
- âœ… Malayalam political memes  
- âœ… Multimodal learning (Image + Text)  
- âœ… Class imbalance handling  
- âœ… GPU acceleration (CUDA)  

---

## ğŸ“Œ Problem Statement

Political memes are multimodal in nature. They contain:

- Visual elements (faces, symbols, logos)
- Embedded text (requires OCR)
- Sarcasm and contextual meaning

Traditional text-only or image-only models fail to capture the complete semantic intent.

This project leverages **CLIP (Contrastive Languageâ€“Image Pretraining)** to extract unified multimodal representations for robust classification.

---

## ğŸ— Architecture Overview

```
Image â†’ CLIP Image Encoder â†’ 512-dim
Text  â†’ CLIP Text Encoder  â†’ 512-dim
Concatenate â†’ 1024-dim Feature Vector
â†’ MLP Classifier â†’ 4 Output Classes
```

### Feature Details

- 512-dim image embedding
- 512-dim text embedding (OCR extracted)
- L2 normalization applied
- Concatenated into 1024-dim feature vector

---

## ğŸ“‚ Dataset Structure

```
meme/
â”‚
â”œâ”€â”€ Train_images/
â”‚   â”œâ”€â”€ 001.jpg
â”‚   â”œâ”€â”€ 002.jpg
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ Train_labels.xlsx
```

### Excel Columns

- `Image_id`
- `Image_name`
- `Level1`
- `Level2` â† Final classification label

---

## ğŸ· Classification Labels (Level2)

1. Support for Party  
2. Support for Person  
3. Troll/Oppose Against Party  
4. Troll/Oppose Against Person  

---

## ğŸ” OCR Pipeline

Text is extracted from memes using:

- `pytesseract`
- PIL image preprocessing

Malayalam support works because:

- Tesseract includes Malayalam language packs
- CLIPâ€™s text encoder handles multilingual tokens reasonably well

---

## ğŸ§  Feature Extraction Model

Model Used:

```
openai/clip-vit-base-patch32
```

CLIP provides strong multimodal embeddings without requiring fine-tuning.

---

## ğŸ‹ï¸ Classifier Architecture

Fully Connected Neural Network:

- Linear(1024 â†’ 768)
- BatchNorm + ReLU + Dropout(0.3)
- Linear(768 â†’ 512)
- BatchNorm + ReLU + Dropout(0.3)
- Linear(512 â†’ 256)
- BatchNorm + ReLU + Dropout(0.3)
- Linear(256 â†’ 4)

---

## âš™ï¸ Training Configuration

- Optimizer: AdamW  
- Learning Rate: 3e-4  
- Weight Decay: 0.01  
- Epochs: 20  
- Batch Size: 32  
- Loss: Weighted CrossEntropy (to handle class imbalance)

---

## ğŸ“Š Performance

Expected performance (dataset dependent):

| Metric | Typical Range |
|--------|---------------|
| Training Accuracy | 85â€“95% |
| Test Accuracy | 80â€“88% |
| Macro F1 Score | 0.75â€“0.85 |

Performance depends heavily on:
- OCR quality
- Label consistency
- Class imbalance severity

---

## ğŸŒ Malayalam Extension

The pipeline was extended to handle **Malayalam political memes**:

- OCR using Tesseract Malayalam model
- Same CLIP architecture
- No structural modifications required

This demonstrates language-agnostic multimodal capability.

---

## ğŸš€ Installation

### Local Setup

```bash
pip install transformers pytesseract pillow scikit-learn tqdm
sudo apt-get install tesseract-ocr
```

### Google Colab

```python
!pip install transformers pytesseract pillow scikit-learn tqdm
!apt-get install tesseract-ocr -y
```

---

## â–¶ï¸ Execution Steps

1. Load dataset from Drive
2. Extract OCR text
3. Generate CLIP embeddings
4. Train classifier
5. Evaluate using classification report

---

## ğŸ”¥ Key Insights

- Multimodal learning significantly outperforms single-modality models
- Class imbalance drastically affects minority recall
- Oversampling can destabilize small datasets
- Weighted loss improves minority class detection
- CLIP converges quickly without full fine-tuning
- OCR quality directly influences final performance

---

## ğŸ“ˆ Future Improvements

- Fine-tune CLIP end-to-end
- Use multilingual CLIP variants
- Replace concatenation with attention-based fusion
- Experiment with focal loss
- Apply stronger vision backbone (ViT-L/14)

---

## ğŸ§‘â€ğŸ’» Project Type

Engineering Project  
Deep Learning | NLP | Multimodal AI  

---

If you found this project useful, feel free to â­ the repository.
